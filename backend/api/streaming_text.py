"""
Text Streaming for Multi-Agent Analysis
Streams LLM responses word-by-word as they're generated
"""

from typing import AsyncGenerator, Dict, Any
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import os


async def stream_agent_analysis(
    agent_name: str, system_prompt: str, user_prompt: str, model: str = "gpt-4o-mini"
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    Stream an agent's analysis text as it's generated by the LLM.

    Args:
        agent_name: Name of the agent (e.g., "Market Analyst")
        system_prompt: System message for the agent
        user_prompt: User message/question for the agent
        model: LLM model to use

    Yields:
        Events with text chunks:
        - agent_text_chunk: Individual text chunk
        - agent_text_complete: Full text when done
    """
    # Initialize streaming LLM
    llm = ChatOpenAI(
        model=model,
        temperature=0.3,
        streaming=True,  # Enable streaming
        api_key=os.getenv("OPENAI_API_KEY"),
    )

    full_text = ""

    # Start streaming
    yield {
        "event": "agent_text_start",
        "agent": agent_name,
        "message": f"{agent_name} is analyzing...",
    }

    try:
        # Stream the response
        async for chunk in llm.astream(
            [SystemMessage(content=system_prompt), HumanMessage(content=user_prompt)]
        ):
            if chunk.content:
                full_text += chunk.content

                # Yield each chunk
                yield {
                    "event": "agent_text_chunk",
                    "agent": agent_name,
                    "chunk": chunk.content,
                    "accumulated_length": len(full_text),
                }

        # Analysis complete
        yield {
            "event": "agent_text_complete",
            "agent": agent_name,
            "full_text": full_text,
            "total_length": len(full_text),
        }

    except Exception as e:
        yield {"event": "agent_error", "agent": agent_name, "error": str(e)}


async def stream_stock_analysis_with_text(
    symbol: str, trading_agents_graph, trade_date: str
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    Stream complete stock analysis with real-time text streaming.

    This version streams the actual LLM responses as they're generated,
    not just progress updates.
    """
    try:
        yield {
            "event": "start",
            "symbol": symbol,
            "message": f"Starting multi-agent analysis for {symbol}",
            "timestamp": trade_date,
        }

        # Agent configurations
        agents = [
            {
                "name": "Market Analyst",
                "system": "You are a veteran market analyst with expertise in technical analysis, chart patterns, and market trends.",
                "prompt": f"Analyze {symbol} from a technical perspective. Include: price action, key indicators (RSI, MACD), support/resistance levels, and trend analysis.",
            },
            {
                "name": "Social Analyst",
                "system": "You are a social media sentiment analyst tracking retail investor psychology and crowd behavior.",
                "prompt": f"Analyze social sentiment for {symbol}. Include: Reddit discussions, Twitter mentions, StockTwits activity, and overall retail sentiment.",
            },
            {
                "name": "News Analyst",
                "system": "You are a news analyst tracking breaking news, corporate events, and market-moving catalysts.",
                "prompt": f"Analyze recent news and events for {symbol}. Include: latest headlines, insider trading, corporate actions, and upcoming catalysts.",
            },
            {
                "name": "Fundamentals Analyst",
                "system": "You are a fundamental analyst evaluating financial health, valuation, and growth prospects.",
                "prompt": f"Analyze {symbol}'s fundamentals. Include: financial ratios, earnings trends, valuation metrics, and competitive position.",
            },
        ]

        agent_results = {}

        # Stream each agent's analysis
        for i, agent_config in enumerate(agents):
            agent_name = agent_config["name"]
            progress = (i / len(agents)) * 100

            yield {"event": "agent_start", "agent": agent_name, "progress": progress}

            # Stream the agent's text analysis
            full_text = ""
            async for text_event in stream_agent_analysis(
                agent_name=agent_name,
                system_prompt=agent_config["system"],
                user_prompt=agent_config["prompt"],
            ):
                # Forward text streaming events
                yield text_event

                # Accumulate full text
                if text_event["event"] == "agent_text_complete":
                    full_text = text_event["full_text"]

            agent_results[agent_name.lower().replace(" ", "_")] = full_text

            progress = ((i + 1) / len(agents)) * 100
            yield {"event": "agent_complete", "agent": agent_name, "progress": progress}

        # Synthesis phase
        yield {"event": "synthesis_start", "message": "Synthesizing agent reports..."}

        # Create synthesis prompt
        synthesis_prompt = f"""
Based on the analysis from all agents, provide a final recommendation for {symbol}.

Market Analysis: {agent_results.get('market_analyst', 'N/A')[:200]}...
Social Sentiment: {agent_results.get('social_analyst', 'N/A')[:200]}...
News Analysis: {agent_results.get('news_analyst', 'N/A')[:200]}...
Fundamentals: {agent_results.get('fundamentals_analyst', 'N/A')[:200]}...

Provide: BUY/SELL/HOLD recommendation with justification.
"""

        # Stream synthesis
        synthesis_text = ""
        async for synthesis_event in stream_agent_analysis(
            agent_name="Investment Synthesizer",
            system_prompt="You are a Chief Investment Officer synthesizing multiple analyst perspectives into actionable recommendations.",
            user_prompt=synthesis_prompt,
        ):
            yield synthesis_event

            if synthesis_event["event"] == "agent_text_complete":
                synthesis_text = synthesis_event["full_text"]

        # Determine recommendation from synthesis
        recommendation = "HOLD"
        if "BUY" in synthesis_text.upper() and synthesis_text.upper().find(
            "BUY"
        ) < synthesis_text.upper().find(
            "SELL",
            (
                synthesis_text.upper().find("BUY") + 1
                if "SELL"
                in synthesis_text.upper()[synthesis_text.upper().find("BUY") :]
                else len(synthesis_text)
            ),
        ):
            recommendation = "BUY"
        elif "SELL" in synthesis_text.upper():
            recommendation = "SELL"

        # Get price data
        import yfinance as yf

        ticker_data = yf.Ticker(symbol.upper())
        current_price = (
            ticker_data.history(period="1d")["Close"].iloc[-1]
            if not ticker_data.history(period="1d").empty
            else 100.0
        )

        target_price = (
            current_price * 1.15 if recommendation == "BUY" else current_price
        )
        stop_loss = (
            current_price * 0.95 if recommendation == "BUY" else current_price * 0.90
        )

        # Final result
        yield {
            "event": "done",
            "symbol": symbol.upper(),
            "recommendation": recommendation,
            "confidence": 0.80,
            "target_price": float(target_price),
            "stop_loss": float(stop_loss),
            "current_price": float(current_price),
            "agent_reports": agent_results,
            "synthesis": synthesis_text,
            "timestamp": trade_date,
        }

    except Exception as e:
        yield {"event": "error", "symbol": symbol, "message": str(e)}
